## Example scripts for running multi-node inference with VLLM on HPCs (Baskerville A100 GPUs and H100 GPUs and Isambard-AI GH200 GPUs)

# Refs
- https://docs.vllm.ai/en/v0.9.2/serving/distributed_serving.html
- https://github.com/vllm-project/vllm/blob/main/examples/online_serving/run_cluster.sh
- [vllm #26028](https://github.com/vllm-project/vllm/issues/26028)
- https://swaglu.com/llama-405b-vllm-slurm-multinode/#step-1-multi-node-slurm-configuration
- https://docs.isambard.ac.uk/user-documentation/guides/containers/apptainer-multi-node/
